{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.data.nuscenes import NuScenesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NU = NuScenesDataset('core/data/datasets/nuscenes',\n",
    "                               0.05, split='mini', task='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = NU.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lidar', 'targets', 'targets_mapped', 'inverse_map'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26507, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item['lidar'].C.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Network Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from core.model import SPVStd, SPVRnn\n",
    "\n",
    "net_id = '@20'\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "    \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load config\n",
    "net_config = json.load(open('core/pretrained/net{}.config'.format(net_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_config['num_classes'] = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load parameters\n",
    "params = torch.load('core/pretrained/init{}'.format(net_id),\n",
    "                 map_location=device)['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(params['classifier.linear.weight'].requires_grad)\n",
    "print(params['upsample.0.transition.net.bn.weight'].requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['stem.0.kernel', 'stem.1.weight', 'stem.1.bias', 'stem.1.running_mean', 'stem.1.running_var', 'stem.1.num_batches_tracked', 'stem.3.kernel', 'stem.4.weight', 'stem.4.bias', 'stem.4.running_mean', 'stem.4.running_var', 'stem.4.num_batches_tracked', 'downsample.0.transition.net.conv.kernel', 'downsample.0.transition.net.bn.weight', 'downsample.0.transition.net.bn.bias', 'downsample.0.transition.net.bn.running_mean', 'downsample.0.transition.net.bn.running_var', 'downsample.0.transition.net.bn.num_batches_tracked', 'downsample.0.feature.0.net.0.net.conv.kernel', 'downsample.0.feature.0.net.0.net.bn.weight', 'downsample.0.feature.0.net.0.net.bn.bias', 'downsample.0.feature.0.net.0.net.bn.running_mean', 'downsample.0.feature.0.net.0.net.bn.running_var', 'downsample.0.feature.0.net.0.net.bn.num_batches_tracked', 'downsample.0.feature.0.net.1.net.conv.kernel', 'downsample.0.feature.0.net.1.net.bn.weight', 'downsample.0.feature.0.net.1.net.bn.bias', 'downsample.0.feature.0.net.1.net.bn.running_mean', 'downsample.0.feature.0.net.1.net.bn.running_var', 'downsample.0.feature.0.net.1.net.bn.num_batches_tracked', 'downsample.0.feature.0.downsample.net.conv.kernel', 'downsample.0.feature.0.downsample.net.bn.weight', 'downsample.0.feature.0.downsample.net.bn.bias', 'downsample.0.feature.0.downsample.net.bn.running_mean', 'downsample.0.feature.0.downsample.net.bn.running_var', 'downsample.0.feature.0.downsample.net.bn.num_batches_tracked', 'downsample.1.transition.net.conv.kernel', 'downsample.1.transition.net.bn.weight', 'downsample.1.transition.net.bn.bias', 'downsample.1.transition.net.bn.running_mean', 'downsample.1.transition.net.bn.running_var', 'downsample.1.transition.net.bn.num_batches_tracked', 'downsample.1.feature.0.net.0.net.conv.kernel', 'downsample.1.feature.0.net.0.net.bn.weight', 'downsample.1.feature.0.net.0.net.bn.bias', 'downsample.1.feature.0.net.0.net.bn.running_mean', 'downsample.1.feature.0.net.0.net.bn.running_var', 'downsample.1.feature.0.net.0.net.bn.num_batches_tracked', 'downsample.1.feature.0.net.1.net.conv.kernel', 'downsample.1.feature.0.net.1.net.bn.weight', 'downsample.1.feature.0.net.1.net.bn.bias', 'downsample.1.feature.0.net.1.net.bn.running_mean', 'downsample.1.feature.0.net.1.net.bn.running_var', 'downsample.1.feature.0.net.1.net.bn.num_batches_tracked', 'downsample.1.feature.0.downsample.net.conv.kernel', 'downsample.1.feature.0.downsample.net.bn.weight', 'downsample.1.feature.0.downsample.net.bn.bias', 'downsample.1.feature.0.downsample.net.bn.running_mean', 'downsample.1.feature.0.downsample.net.bn.running_var', 'downsample.1.feature.0.downsample.net.bn.num_batches_tracked', 'downsample.2.transition.net.conv.kernel', 'downsample.2.transition.net.bn.weight', 'downsample.2.transition.net.bn.bias', 'downsample.2.transition.net.bn.running_mean', 'downsample.2.transition.net.bn.running_var', 'downsample.2.transition.net.bn.num_batches_tracked', 'downsample.2.feature.0.net.0.net.conv.kernel', 'downsample.2.feature.0.net.0.net.bn.weight', 'downsample.2.feature.0.net.0.net.bn.bias', 'downsample.2.feature.0.net.0.net.bn.running_mean', 'downsample.2.feature.0.net.0.net.bn.running_var', 'downsample.2.feature.0.net.0.net.bn.num_batches_tracked', 'downsample.2.feature.0.net.1.net.conv.kernel', 'downsample.2.feature.0.net.1.net.bn.weight', 'downsample.2.feature.0.net.1.net.bn.bias', 'downsample.2.feature.0.net.1.net.bn.running_mean', 'downsample.2.feature.0.net.1.net.bn.running_var', 'downsample.2.feature.0.net.1.net.bn.num_batches_tracked', 'downsample.2.feature.0.downsample.net.conv.kernel', 'downsample.2.feature.0.downsample.net.bn.weight', 'downsample.2.feature.0.downsample.net.bn.bias', 'downsample.2.feature.0.downsample.net.bn.running_mean', 'downsample.2.feature.0.downsample.net.bn.running_var', 'downsample.2.feature.0.downsample.net.bn.num_batches_tracked', 'downsample.2.feature.1.net.0.net.conv.kernel', 'downsample.2.feature.1.net.0.net.bn.weight', 'downsample.2.feature.1.net.0.net.bn.bias', 'downsample.2.feature.1.net.0.net.bn.running_mean', 'downsample.2.feature.1.net.0.net.bn.running_var', 'downsample.2.feature.1.net.0.net.bn.num_batches_tracked', 'downsample.2.feature.1.net.1.net.conv.kernel', 'downsample.2.feature.1.net.1.net.bn.weight', 'downsample.2.feature.1.net.1.net.bn.bias', 'downsample.2.feature.1.net.1.net.bn.running_mean', 'downsample.2.feature.1.net.1.net.bn.running_var', 'downsample.2.feature.1.net.1.net.bn.num_batches_tracked', 'downsample.3.transition.net.conv.kernel', 'downsample.3.transition.net.bn.weight', 'downsample.3.transition.net.bn.bias', 'downsample.3.transition.net.bn.running_mean', 'downsample.3.transition.net.bn.running_var', 'downsample.3.transition.net.bn.num_batches_tracked', 'downsample.3.feature.0.net.0.net.conv.kernel', 'downsample.3.feature.0.net.0.net.bn.weight', 'downsample.3.feature.0.net.0.net.bn.bias', 'downsample.3.feature.0.net.0.net.bn.running_mean', 'downsample.3.feature.0.net.0.net.bn.running_var', 'downsample.3.feature.0.net.0.net.bn.num_batches_tracked', 'downsample.3.feature.0.net.1.net.conv.kernel', 'downsample.3.feature.0.net.1.net.bn.weight', 'downsample.3.feature.0.net.1.net.bn.bias', 'downsample.3.feature.0.net.1.net.bn.running_mean', 'downsample.3.feature.0.net.1.net.bn.running_var', 'downsample.3.feature.0.net.1.net.bn.num_batches_tracked', 'downsample.3.feature.0.downsample.net.conv.kernel', 'downsample.3.feature.0.downsample.net.bn.weight', 'downsample.3.feature.0.downsample.net.bn.bias', 'downsample.3.feature.0.downsample.net.bn.running_mean', 'downsample.3.feature.0.downsample.net.bn.running_var', 'downsample.3.feature.0.downsample.net.bn.num_batches_tracked', 'upsample.0.transition.net.conv.kernel', 'upsample.0.transition.net.bn.weight', 'upsample.0.transition.net.bn.bias', 'upsample.0.transition.net.bn.running_mean', 'upsample.0.transition.net.bn.running_var', 'upsample.0.transition.net.bn.num_batches_tracked', 'upsample.0.feature.0.net.0.net.conv.kernel', 'upsample.0.feature.0.net.0.net.bn.weight', 'upsample.0.feature.0.net.0.net.bn.bias', 'upsample.0.feature.0.net.0.net.bn.running_mean', 'upsample.0.feature.0.net.0.net.bn.running_var', 'upsample.0.feature.0.net.0.net.bn.num_batches_tracked', 'upsample.0.feature.0.net.1.net.conv.kernel', 'upsample.0.feature.0.net.1.net.bn.weight', 'upsample.0.feature.0.net.1.net.bn.bias', 'upsample.0.feature.0.net.1.net.bn.running_mean', 'upsample.0.feature.0.net.1.net.bn.running_var', 'upsample.0.feature.0.net.1.net.bn.num_batches_tracked', 'upsample.0.feature.0.downsample.net.conv.kernel', 'upsample.0.feature.0.downsample.net.bn.weight', 'upsample.0.feature.0.downsample.net.bn.bias', 'upsample.0.feature.0.downsample.net.bn.running_mean', 'upsample.0.feature.0.downsample.net.bn.running_var', 'upsample.0.feature.0.downsample.net.bn.num_batches_tracked', 'upsample.1.transition.net.conv.kernel', 'upsample.1.transition.net.bn.weight', 'upsample.1.transition.net.bn.bias', 'upsample.1.transition.net.bn.running_mean', 'upsample.1.transition.net.bn.running_var', 'upsample.1.transition.net.bn.num_batches_tracked', 'upsample.1.feature.0.net.0.net.conv.kernel', 'upsample.1.feature.0.net.0.net.bn.weight', 'upsample.1.feature.0.net.0.net.bn.bias', 'upsample.1.feature.0.net.0.net.bn.running_mean', 'upsample.1.feature.0.net.0.net.bn.running_var', 'upsample.1.feature.0.net.0.net.bn.num_batches_tracked', 'upsample.1.feature.0.net.1.net.conv.kernel', 'upsample.1.feature.0.net.1.net.bn.weight', 'upsample.1.feature.0.net.1.net.bn.bias', 'upsample.1.feature.0.net.1.net.bn.running_mean', 'upsample.1.feature.0.net.1.net.bn.running_var', 'upsample.1.feature.0.net.1.net.bn.num_batches_tracked', 'upsample.1.feature.0.downsample.net.conv.kernel', 'upsample.1.feature.0.downsample.net.bn.weight', 'upsample.1.feature.0.downsample.net.bn.bias', 'upsample.1.feature.0.downsample.net.bn.running_mean', 'upsample.1.feature.0.downsample.net.bn.running_var', 'upsample.1.feature.0.downsample.net.bn.num_batches_tracked', 'upsample.2.transition.net.conv.kernel', 'upsample.2.transition.net.bn.weight', 'upsample.2.transition.net.bn.bias', 'upsample.2.transition.net.bn.running_mean', 'upsample.2.transition.net.bn.running_var', 'upsample.2.transition.net.bn.num_batches_tracked', 'upsample.2.feature.0.net.0.net.conv.kernel', 'upsample.2.feature.0.net.0.net.bn.weight', 'upsample.2.feature.0.net.0.net.bn.bias', 'upsample.2.feature.0.net.0.net.bn.running_mean', 'upsample.2.feature.0.net.0.net.bn.running_var', 'upsample.2.feature.0.net.0.net.bn.num_batches_tracked', 'upsample.2.feature.0.net.1.net.conv.kernel', 'upsample.2.feature.0.net.1.net.bn.weight', 'upsample.2.feature.0.net.1.net.bn.bias', 'upsample.2.feature.0.net.1.net.bn.running_mean', 'upsample.2.feature.0.net.1.net.bn.running_var', 'upsample.2.feature.0.net.1.net.bn.num_batches_tracked', 'upsample.2.feature.0.downsample.net.conv.kernel', 'upsample.2.feature.0.downsample.net.bn.weight', 'upsample.2.feature.0.downsample.net.bn.bias', 'upsample.2.feature.0.downsample.net.bn.running_mean', 'upsample.2.feature.0.downsample.net.bn.running_var', 'upsample.2.feature.0.downsample.net.bn.num_batches_tracked', 'upsample.3.transition.net.conv.kernel', 'upsample.3.transition.net.bn.weight', 'upsample.3.transition.net.bn.bias', 'upsample.3.transition.net.bn.running_mean', 'upsample.3.transition.net.bn.running_var', 'upsample.3.transition.net.bn.num_batches_tracked', 'upsample.3.feature.0.net.0.net.conv.kernel', 'upsample.3.feature.0.net.0.net.bn.weight', 'upsample.3.feature.0.net.0.net.bn.bias', 'upsample.3.feature.0.net.0.net.bn.running_mean', 'upsample.3.feature.0.net.0.net.bn.running_var', 'upsample.3.feature.0.net.0.net.bn.num_batches_tracked', 'upsample.3.feature.0.net.1.net.conv.kernel', 'upsample.3.feature.0.net.1.net.bn.weight', 'upsample.3.feature.0.net.1.net.bn.bias', 'upsample.3.feature.0.net.1.net.bn.running_mean', 'upsample.3.feature.0.net.1.net.bn.running_var', 'upsample.3.feature.0.net.1.net.bn.num_batches_tracked', 'upsample.3.feature.0.downsample.net.conv.kernel', 'upsample.3.feature.0.downsample.net.bn.weight', 'upsample.3.feature.0.downsample.net.bn.bias', 'upsample.3.feature.0.downsample.net.bn.running_mean', 'upsample.3.feature.0.downsample.net.bn.running_var', 'upsample.3.feature.0.downsample.net.bn.num_batches_tracked', 'point_transforms.0.net.conv.weight', 'point_transforms.0.net.conv.bias', 'point_transforms.0.net.bn.weight', 'point_transforms.0.net.bn.bias', 'point_transforms.0.net.bn.running_mean', 'point_transforms.0.net.bn.running_var', 'point_transforms.0.net.bn.num_batches_tracked', 'point_transforms.1.net.conv.weight', 'point_transforms.1.net.conv.bias', 'point_transforms.1.net.bn.weight', 'point_transforms.1.net.bn.bias', 'point_transforms.1.net.bn.running_mean', 'point_transforms.1.net.bn.running_var', 'point_transforms.1.net.bn.num_batches_tracked', 'point_transforms.2.net.conv.weight', 'point_transforms.2.net.conv.bias', 'point_transforms.2.net.bn.weight', 'point_transforms.2.net.bn.bias', 'point_transforms.2.net.bn.running_mean', 'point_transforms.2.net.bn.running_var', 'point_transforms.2.net.bn.num_batches_tracked'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del params['classifier.linear.weight']\n",
    "del params['classifier.linear.bias']\n",
    "params.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPVNAS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the model\n",
    "model = SPVStd(net_config, params, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier.linear.weight\n",
      "torch.Size([17, 128])\n",
      "classifier.linear.bias\n",
      "torch.Size([17])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "                if name not in ['classifier.linear.weight', 'classifier.linear.bias']:\n",
    "                    param.requires_grad = False\n",
    "                \n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        print(name)\n",
    "        print(param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a random input vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8170, -1.9681, -2.0076,  ...,  0.6973, -0.8072, -2.0817],\n",
      "        [ 1.0878, -1.8475, -1.1225,  ...,  1.9824, -1.1658, -2.4323],\n",
      "        [-3.2777, -1.4396, -2.9076,  ...,  0.4465,  1.9437, -2.5443],\n",
      "        ...,\n",
      "        [-2.5257, -2.6721, -2.3396,  ...,  4.2012,  0.1960, -2.4443],\n",
      "        [-1.0198, -1.8608, -1.8722,  ...,  2.4786, -0.8197, -1.2147],\n",
      "        [-0.3618, -2.2857, -2.6285,  ...,  4.3616, -1.0914, -2.6978]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from torchsparse import SparseTensor\n",
    "\n",
    "sample_feat = torch.randn(1000, 4)\n",
    "sample_coord = torch.randn(1000, 4).random_(997)\n",
    "sample_coord[:, -1] = 0\n",
    "        \n",
    "x = SparseTensor(sample_feat, sample_coord.int()).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(model.forward(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x.F))\n",
    "sample_feat = torch.randn(1000, 4)\n",
    "sample_coord = torch.randn(1000, 4).random_(997)\n",
    "sample_coord[:, -1] = 0\n",
    "        \n",
    "x = SparseTensor(sample_feat, sample_coord.int())\n",
    "print(type(x.F))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With an actual input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "item['lidar'].C[:, -1] = 0 #Set the batch dimension to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x = item['lidar'].to(device)\n",
    "    y = model.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26507, 19])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.data.mappings import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0078, 0.0024, 0.0024, 0.0011, 0.0055, 0.0028, 0.0013, 0.0016, 0.0290,\n",
      "        0.0043, 0.0353, 0.0260, 0.4114, 0.0291, 0.2651, 0.0043, 0.1681, 0.0019,\n",
      "        0.0007], device='cuda:0')\n",
      "tensor(0.4114, device='cuda:0')\n",
      "tensor(12, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "p = torch.nn.functional.softmax(y[0], dim=0)\n",
    "print(p)\n",
    "print(torch.max(p))\n",
    "print(torch.argmax(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5, dtype=torch.uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item['targets'].F[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dimension matches which is good, also 19 is for the 19 classes they keep in SPVNAS. It seems that softmax isn't a part of their model? Also it is hard to tell how the predictions are matching up with everything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPVRnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the model\n",
    "model = SPVRnn(net_config, params, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsparse import SparseTensor\n",
    "\n",
    "sample_feat = torch.randn(1000, 4)\n",
    "sample_coord = torch.randn(1000, 4).random_(997)\n",
    "sample_coord[:, -1] = 0\n",
    "        \n",
    "x = SparseTensor(sample_feat, sample_coord.int()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "#     x = item['lidar'].to(device)\n",
    "    y = model.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchsparse.point_tensor.PointTensor'>\n",
      "torch.Size([1000, 48])\n"
     ]
    }
   ],
   "source": [
    "print(type(y))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0., 1241.,  162.,  560.], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.C[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0, 1241,  162,  560], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.C[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchsparse.nn as spnn\n",
    "from torchsparse import SparseTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_feat = torch.randn(1000, 4)\n",
    "sample_coord = torch.randn(1000, 4).random_(997)\n",
    "sample_coord[:, -1] = 0\n",
    "        \n",
    "x = SparseTensor(sample_feat, sample_coord.int()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 32]) torch.Size([1000, 4])\n"
     ]
    }
   ],
   "source": [
    "conv = spnn.Conv3d(4, 32, kernel_size=3, stride=1).to(device)\n",
    "y = conv.forward(x)\n",
    "print(y.F.shape, y.C.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
