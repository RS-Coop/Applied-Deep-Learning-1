{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Robotics Week 01: \n",
    "## Predictive Model for Collision Avoidance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wider and more powerfull intelligence is necessary for the future of robotics. Currently, robots -- while capable of many things -- are often static, pre-programmed, and only operational in specificaly tailored environments. The vision for the future are dynamic robots capable of intelligently operating in changing environments. Machine learning -- which includes deep learning among other sub-fields -- provides a highly promising path forward. However, robots are a unique implementation of machine learning with many complications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the more common challenges in machine learning apply to robotics as well. For example: time, resources, and data are all still needed for the learning process, and deployment can provide many unexpected problems. There are also some complications in robotics that are somewhat unique. Safety is a huge concern, so any failure in a robotic system must be handled appropriately with potentialy dire concequences. Furthermore, robots often have limited processing capabilites, so latency and resource availability are constraining. This is further problematic due to the fact that robots are operating in real-time and need to make immediate decisions. These are only some of the challenges, but it certainly is a hard problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If these difficulties can be overcome then there is a broad array of applications for machine learning. To name a few broad classes: controls, state estimation, perception, coordination, modular systems, and many more. A classic example is computer vision which can (and does) allow robots to detect objects like people -- useful for human robot interaction scenarios. Just about any aspect of robotics could (and currently does) benefit form machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this tutorial is to train a network for collision detection and deploy this in a robotic simulation. The input to this network are distance sensor values -- which could be a sonic sensor, LiDAR, etc. -- and the steering angle. The output is a binary indicator of collision or no collision in the next time step. Without the steering angle the model could sometimes incorrectly predict as certain collision scenarios are dependent an the action taken.\n",
    "\n",
    "The robot that will be used for this tutorial has 5 sensors spread across its front and a bumper sensor to detect an actual collision. Training data is collected by having the robot randomly explore a simulation environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code (Description and Changes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tutorial provides a large amount of code to be used in the collision avoidance exercise. We will describe the aspects of this code and any changes that we have made to it. Notably, the tutorial uses PyTorch as its deep learning library, but we will be converting everything into Tensorflow for a deeper learning experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ExploreAndCollect.py:** This python file loads the simulator and has the robot move throughout the envrionment randomly. The sensor data is collected and stored in the \"SensorData\" folder for use in training the network later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PreProcessing.py:** This python file loads the sensor data and preforms a few basic pre-processing tasks. Namely: it labels the data, duplicates the collision data, and then divides it into training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MakeItLearn.py:** This file use loads the saved sensor data, and then uses PyTorch to build and train a basic dense network. This model is then saved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PlayingTheModel.py:** This file loads the simulator, loads the network model, and has the robot begin travelling to a pre-defined destination. Along the way the robot uses the network to check for collisions, and if detected take alternative action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be leaving **ExploreAndCollect** mostly unchanged (excepting a few simulation details), but will avoid **PreProcessing** and **MakeItLearn**. Instead this jupyter notebook will handle the details of building a network in Tensorflow, training it, and running the final simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global vars\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8001, 7)\n"
     ]
    }
   ],
   "source": [
    "#Load and preprocess the training data.\n",
    "sensor_data = np.loadtxt('./SensorData/SensorData.txt')\n",
    "print(sensor_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 8,001 data each with 7 dimensions. The first 5 rows are the distance sensors, then the steering angle, and finally a binary indicator for collision. We don't just want the robot to predict a collision right as it collides, we want it to do so enough beforehand to change its direction. The next step is to mark data before the collision as a collision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "SensorDataRows = []\n",
    "for i in range(20):\n",
    "    SensorDataRows.append(np.roll(sensor_data[:,-1],-i-1))\n",
    "for i in range(20):\n",
    "    sensor_data[:,-1] += SensorDataRows[i]\n",
    "    \n",
    "print(max(sensor_data[:,-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Becuase the data was gathered from the robot randomly moving around in a somewhat sparse environment, we may not have that much collision data. To fix this we will duplicate our collision data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18921, 7)\n"
     ]
    }
   ],
   "source": [
    "collision_data = sensor_data[sensor_data[:,-1] > 0]\n",
    "\n",
    "#Duplicate 10 times\n",
    "for i in range(10):\n",
    "    sensor_data = np.append(sensor_data, collision_data, axis=0)\n",
    "    \n",
    "print(sensor_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see we have increased the total data by a roughly 10000. The last step is to split our data into training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13244, 6)\n",
      "(5677, 6)\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(sensor_data) #Mix the data around\n",
    "\n",
    "split = int(0.70*sensor_data.shape[0])\n",
    "\n",
    "train_data = tf.constant(sensor_data[:split,:-1])\n",
    "train_labels = tf.constant(sensor_data[:split,-1])\n",
    "\n",
    "test_data = tf.constant(sensor_data[split:,:-1])\n",
    "test_labels = tf.constant(sensor_data[split:,-1])\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build a simple linear network for our collision prediciton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Network\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.Input(shape=6),\n",
    "    keras.layers.Dense(100, activation='tanh'),\n",
    "    keras.layers.Dense(50, activation='tanh'),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss=keras.losses.MeanSquaredError(),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "414/414 [==============================] - 0s 540us/step - loss: 0.0452 - accuracy: 0.9571\n",
      "Epoch 2/20\n",
      "414/414 [==============================] - 0s 533us/step - loss: 0.0174 - accuracy: 0.9870\n",
      "Epoch 3/20\n",
      "414/414 [==============================] - 0s 528us/step - loss: 0.0148 - accuracy: 0.9887\n",
      "Epoch 4/20\n",
      "414/414 [==============================] - 0s 570us/step - loss: 0.0140 - accuracy: 0.9890\n",
      "Epoch 5/20\n",
      "414/414 [==============================] - 0s 540us/step - loss: 0.0131 - accuracy: 0.9890\n",
      "Epoch 6/20\n",
      "414/414 [==============================] - 0s 543us/step - loss: 0.0128 - accuracy: 0.9894\n",
      "Epoch 7/20\n",
      "414/414 [==============================] - 0s 582us/step - loss: 0.0111 - accuracy: 0.9907\n",
      "Epoch 8/20\n",
      "414/414 [==============================] - 0s 548us/step - loss: 0.0114 - accuracy: 0.9903\n",
      "Epoch 9/20\n",
      "414/414 [==============================] - 0s 548us/step - loss: 0.0107 - accuracy: 0.9912\n",
      "Epoch 10/20\n",
      "414/414 [==============================] - 0s 564us/step - loss: 0.0105 - accuracy: 0.9907\n",
      "Epoch 11/20\n",
      "414/414 [==============================] - 0s 553us/step - loss: 0.0097 - accuracy: 0.9918\n",
      "Epoch 12/20\n",
      "414/414 [==============================] - 0s 563us/step - loss: 0.0107 - accuracy: 0.9909\n",
      "Epoch 13/20\n",
      "414/414 [==============================] - 0s 569us/step - loss: 0.0098 - accuracy: 0.9915\n",
      "Epoch 14/20\n",
      "414/414 [==============================] - 0s 562us/step - loss: 0.0097 - accuracy: 0.9916\n",
      "Epoch 15/20\n",
      "414/414 [==============================] - 0s 540us/step - loss: 0.0103 - accuracy: 0.9903\n",
      "Epoch 16/20\n",
      "414/414 [==============================] - 0s 538us/step - loss: 0.0094 - accuracy: 0.9921\n",
      "Epoch 17/20\n",
      "414/414 [==============================] - 0s 553us/step - loss: 0.0094 - accuracy: 0.9913\n",
      "Epoch 18/20\n",
      "414/414 [==============================] - 0s 551us/step - loss: 0.0096 - accuracy: 0.9912\n",
      "Epoch 19/20\n",
      "414/414 [==============================] - 0s 576us/step - loss: 0.0091 - accuracy: 0.9923\n",
      "Epoch 20/20\n",
      "414/414 [==============================] - 0s 560us/step - loss: 0.0082 - accuracy: 0.9921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f51baf84d00>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_labels, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               700       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 5,801\n",
      "Trainable params: 5,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.0, shape=(), dtype=float64)\n",
      "tf.Tensor([100.         79.         60.         67.         28.        276.3692078], shape=(6,), dtype=float64)\n",
      "tf.Tensor([[0.94886917]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "idx = 10\n",
    "print(test_labels[idx])\n",
    "print(test_data[idx])\n",
    "\n",
    "test = np.expand_dims(test_data[idx],0)\n",
    "\n",
    "pred = model(test, training=False)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to a weird bug with Pygame and Jupyter combination, you can only run teh cell below once, and then you need to reset the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100.  97. 100.]\n",
      "[100. 100. 100.  90. 100.]\n",
      "[100. 100. 100.  84. 100.]\n",
      "[100. 100. 100.  77. 100.]\n",
      "[100. 100. 100.  70. 100.]\n",
      "[100. 100. 100.  64. 100.]\n",
      "[100. 100. 100.  57. 100.]\n",
      "[100. 100. 100.  51.  44.]\n",
      "[100. 100. 100.  44.  38.]\n",
      "[100. 100. 100.  38.  31.]\n",
      "[100. 100. 100.  31.  25.]\n",
      "[100. 100. 100.  33.  21.]\n",
      "[100. 100. 100.  37.  19.]\n",
      "[100. 100. 100.  43.  18.]\n",
      "[100. 100. 100.  53.  18.]\n",
      "[100. 100. 100.  67.  20.]\n",
      "[100. 100. 100.  88.  23.]\n",
      "[100. 100. 100. 100.  28.]\n",
      "[100. 100. 100. 100.  36.]\n",
      "[100. 100. 100. 100.  46.]\n",
      "[100. 100. 100. 100.  60.]\n",
      "[100. 100. 100. 100.  79.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100.  98.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100.  90. 100. 100. 100.]\n",
      "[100.  80. 100. 100. 100.]\n",
      "[100.  70. 100. 100. 100.]\n",
      "[ 88.  66. 100. 100. 100.]\n",
      "[ 75.  64. 100. 100. 100.]\n",
      "[ 66.  64. 100. 100. 100.]\n",
      "[ 59.  65. 100. 100. 100.]\n",
      "[ 54. 100. 100. 100. 100.]\n",
      "[ 50. 100. 100. 100. 100.]\n",
      "[ 49. 100. 100. 100.  98.]\n",
      "[ 49. 100. 100. 100.  91.]\n",
      "[100. 100. 100. 100.  86.]\n",
      "[100. 100. 100. 100.  82.]\n",
      "[100. 100. 100. 100.  79.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100.  97. 100.]\n",
      "[100. 100. 100.  85. 100.]\n",
      "[100. 100. 100.  88.  68.]\n",
      "[100. 100. 100.  94.  63.]\n",
      "[100. 100. 100. 100.  62.]\n",
      "[100. 100. 100. 100.  62.]\n",
      "[100. 100. 100. 100.  66.]\n",
      "[100. 100. 100. 100.  72.]\n",
      "[100. 100. 100. 100.  82.]\n",
      "[100. 100. 100. 100.  95.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100.  95.]\n",
      "[100. 100. 100. 100.  90.]\n",
      "[100. 100. 100.  99.  84.]\n",
      "[100. 100. 100.  93.  79.]\n",
      "[100. 100. 100.  87.  73.]\n",
      "[100. 100. 100.  81.  68.]\n",
      "[100. 100. 100.  75.  62.]\n",
      "[100. 100. 100.  69.  57.]\n",
      "[100. 100. 100.  63.  51.]\n",
      "[100. 100. 100.  57.  46.]\n",
      "[100. 100. 100.  51.  40.]\n",
      "[100. 100. 100.  44.  35.]\n",
      "[100. 100. 100.  38.  29.]\n",
      "[100. 100. 100.  32.  23.]\n",
      "[100. 100. 100.  35.  20.]\n",
      "[100. 100. 100.  40.  18.]\n",
      "[100. 100. 100.  48.  18.]\n",
      "[100. 100. 100.  60.  19.]\n",
      "[100. 100. 100.  78.  22.]\n",
      "[100. 100. 100. 100.  26.]\n",
      "[100. 100. 100. 100.  32.]\n",
      "[100. 100. 100. 100.  41.]\n",
      "[100. 100. 100. 100.  53.]\n",
      "[100. 100. 100. 100.  70.]\n",
      "[100. 100. 100. 100.  92.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100. 100.]\n",
      "[100. 100. 100. 100.  88.]\n",
      "[100. 100. 100. 100.  84.]\n",
      "[100. 100. 100. 100.  80.]\n",
      "[100. 100. 100. 100.  77.]\n",
      "[100. 100. 100. 100.  73.]\n",
      "[100. 100. 100. 100.  70.]\n",
      "[100.  99. 100. 100.  67.]\n",
      "[ 97.  97. 100. 100.  65.]\n",
      "[ 90.  90. 100. 100.  52.]\n",
      "[ 83.  83. 100. 100.  57.]\n",
      "[ 75.  75. 100. 100.  68.]\n",
      "MISSION COMPLETE!\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Running the simulation\n",
    "from PlayingTheModel import runSim\n",
    "#loc can be any starting location of 1,2,3,4\n",
    "runSim(model, loc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
